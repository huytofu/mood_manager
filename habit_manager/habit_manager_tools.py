from typing import List, Dict, Any, Optional
from pydantic import BaseModel, Field
from langchain_core.tools import tool
from datetime import datetime, timedelta
import uuid

# Import basic habit functions for direct calls (similar to call_audio_endpoint pattern)
from utils.habit_utils import (
    _create_micro_habit_record,
    _create_epic_habit_record,
    _assign_micro_to_epic_record,
    _plan_flexible_habits_timing,
    _record_daily_mood,
    _get_daily_habit_list_organized,
    _track_habit_completion_record,
    _calculate_basic_habit_trends,
    _calculate_basic_epic_progress,
    _get_habit_by_id,
    _get_epic_habit_by_id,
    _get_mood_records,
    _get_completion_records,
    _get_all_user_completions,
    get_user_habit_limits
)

# =============================================================================
# TOOL SCHEMAS
# =============================================================================

# BASIC OPERATIONS SCHEMAS (for direct calls)
class MainHabitOperationInput(BaseModel):
    operation: str = Field(..., description="Operation name: create_micro_habit, create_epic_habit, assign_micro_to_epic")
    params: Dict[str, Any] = Field(..., description="Parameters for the habit operation")

class DailyExecutionInput(BaseModel):
    operation: str = Field(..., description="Operation name: track_completion, record_mood, get_daily_habits")
    params: Dict[str, Any] = Field(..., description="Parameters for the daily execution operation")

class ProgressTrackingInput(BaseModel):
    operation: str = Field(..., description="Operation name: calculate_trends, calculate_epic_progress")
    params: Dict[str, Any] = Field(..., description="Parameters for the progress tracking operation")

# Schema removed - create_comprehensive_habit_plan function was removed
# Schema removed - generate_habit_recommendations function was removed

class FinalHabitAnswerInput(BaseModel):
    intervention_type: str = Field(..., description="Type of intervention: 'habit_creation', 'habit_analysis', 'habit_modification', or 'error'")
    habit_plan: Optional[Dict[str, Any]] = Field(default=None, description="Habit plan result from main habit operations")
    analysis_result: Optional[Dict[str, Any]] = Field(default=None, description="Analysis result from advanced analytics tools")
    recommendations: Optional[List[str]] = Field(default=None, description="Recommendations generated by LLM and extended with mood-supporting habits")
    error_message: Optional[str] = Field(default=None, description="Error message if intervention_type is 'error'")

# ADVANCED ANALYTICS SCHEMAS
class AnalyzeUnderperformingHabitsInput(BaseModel):
    user_id: str = Field(..., description="User identifier")
    time_period: str = Field(default="monthly", description="Time period for analysis")
    threshold: float = Field(default=0.3, description="Completion rate threshold below which habits are considered underperforming")

class AnalyzeLaggingEpicProgressInput(BaseModel):
    user_id: str = Field(..., description="User identifier")
    epic_habit_id: str = Field(..., description="Epic habit identifier")
    target_progress_rate: Optional[float] = Field(default=None, description="Expected progress rate, if None calculates from target_completion_date")

class AnalyzeHabitInteractionsInput(BaseModel):
    user_id: str = Field(..., description="User identifier")
    time_period: str = Field(default="monthly", description="Time period for analysis")
    interaction_type: str = Field(default="all", description="Type of interactions to detect: synchronous, antagonistic, or all")

class AnalyzeMoodHabitCorrelationInput(BaseModel):
    user_id: str = Field(..., description="User identifier")
    habit_id: Optional[str] = Field(default=None, description="Specific habit ID, or None for all habits")
    time_period: str = Field(default="monthly", description="Time period for analysis")

class GenerateHabitInsightsInput(BaseModel):
    user_id: str = Field(..., description="User identifier")
    habit_id: Optional[str] = Field(default=None, description="Specific habit ID, or None for all habits")
    insight_type: str = Field(default="comprehensive", description="Type of insights: completion_patterns, timing_optimization, or comprehensive")

class RecommendMoodSupportingHabitsInput(BaseModel):
    mood_state: str = Field(..., description="Current mood state: 'stress' or 'depression'")
    is_crisis: bool = Field(default=False, description="Whether user is in crisis state")
    is_depressed: bool = Field(default=False, description="Whether user is depressed")
    crisis_level: int = Field(default=0, description="Crisis level 0-10 for stress gradation")

class HabitOutput(BaseModel):
    is_created: bool = Field(..., description="Whether habit operation was successful")
    habit_id: Optional[str] = Field(default=None, description="ID of the created/modified habit")
    plan_id: Optional[str] = Field(default=None, description="ID of the created plan")

class FinalHabitAnswerOutput(BaseModel):
    habit_plan: Optional[HabitOutput] = Field(default=None, description="Habit creation/modification results")
    analysis: Optional[Dict[str, Any]] = Field(default=None, description="Analysis results")
    recommendations: List[str] = Field(..., description="List of actionable recommendations for the user")
    intervention_type: str = Field(..., description="Type of intervention performed")
    error_type: Optional[str] = Field(default=None, description="Error type if intervention failed, None otherwise")

# =============================================================================
# BASIC HABIT OPERATIONS (similar to call_audio_endpoint)
# =============================================================================

@tool("main_habit_operations", args_schema=MainHabitOperationInput)
async def main_habit_operations(operation: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tool Purpose: Execute main habit operations (create habits, assign to epics).
    
    Args:
    - operation (str): Operation name (create_micro_habit, create_epic_habit, assign_micro_to_epic)
    - params (Dict[str, Any]): Parameters for the habit operation
    
    Returns:
    - Dict containing: success (bool), data (Any), operation (str), error (str if failed)
    """
    try:
        if operation == "create_micro_habit":
            result = await _create_micro_habit_record(
                user_id=params.get("user_id"),
                name=params.get("name"),
                category=params.get("category"),
                intrinsic_score=params.get("intrinsic_score", 1),
                scheduling=params.get("scheduling", {}),
                assets=params.get("assets", [])
            )
        elif operation == "create_epic_habit":
            result = await _create_epic_habit_record(
                user_id=params.get("user_id"),
                name=params.get("name"),
                description=params.get("description"),
                target_completion_date=params.get("target_completion_date"),
                priority_level=params.get("priority_level", 1)
            )
        elif operation == "assign_micro_to_epic":
            result = await _assign_micro_to_epic_record(
                micro_habit_id=params.get("micro_habit_id"),
                epic_habit_id=params.get("epic_habit_id")
            )
        else:
            raise ValueError(f"Unknown main habit operation: {operation}")
        
        return {
            "success": True,
            "data": result,
            "operation": operation
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "operation": operation
        }

@tool("daily_execution_operations", args_schema=DailyExecutionInput)
async def daily_execution_operations(operation: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tool Purpose: Execute daily habit execution operations (track completions, record mood, get daily habits).
    
    Args:
    - operation (str): Operation name (record_mood, get_daily_habits, plan_flexible_habits)
    - params (Dict[str, Any]): Parameters for the daily execution operation
    
    Returns:
    - Dict containing: success (bool), data (Any), operation (str), error (str if failed)
    """
    try:
        if operation == "record_mood":
            result = await _record_daily_mood(
                user_id=params.get("user_id"),
                mood_score=params.get("mood_score"),
                is_crisis=params.get("is_crisis", False),
                is_depressed=params.get("is_depressed", False),
                notes=params.get("notes", "")
            )
        elif operation == "get_daily_habits":
            result = await _get_daily_habit_list_organized(
                user_id=params.get("user_id"),
                target_date=params.get("target_date")
            )
        elif operation == "plan_flexible_habits":
            result = await _plan_flexible_habits_timing(
                user_id=params.get("user_id"),
                date=params.get("date"),
                available_time_slots=params.get("available_time_slots"),
                energy_level=params.get("energy_level", 5)
            )
        else:
            raise ValueError(f"Unknown daily execution operation: {operation}")
        
        return {
            "success": True,
            "data": result,
            "operation": operation
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "operation": operation
        }

@tool("progress_tracking_operations", args_schema=ProgressTrackingInput)
async def progress_tracking_operations(operation: str, params: Dict[str, Any]) -> Dict[str, Any]:
    """
    Tool Purpose: Execute progress tracking operations (calculate trends, epic progress).
    
    Args:
    - operation (str): Operation name (track_completion, calculate_trends, calculate_epic_progress)
    - params (Dict[str, Any]): Parameters for the progress tracking operation
    
    Returns:
    - Dict containing: success (bool), data (Any), operation (str), error (str if failed)
    """
    try:
        if operation == "track_completion":
            result = await _track_habit_completion_record(
                user_id=params.get("user_id"),
                habit_id=params.get("habit_id"),
                completion_score=params.get("completion_score"),
                notes=params.get("notes", ""),
                completion_date=params.get("completion_date")
            )
        elif operation == "calculate_trends":
            result = await _calculate_basic_habit_trends(
                user_id=params.get("user_id"),
                time_period=params.get("time_period", "weekly")
            )
        elif operation == "calculate_epic_progress":
            result = await _calculate_basic_epic_progress(
                epic_habit_id=params.get("epic_habit_id"),
                time_period=params.get("time_period", "all_time")
            )
        else:
            raise ValueError(f"Unknown progress tracking operation: {operation}")
        
        return {
            "success": True,
            "data": result,
            "operation": operation
        }
        
    except Exception as e:
        return {
            "success": False,
            "error": str(e),
            "operation": operation
        }


# =============================================================================
# FINAL ANSWER TOOL
# =============================================================================

@tool("final_habit_answer", args_schema=FinalHabitAnswerInput)
def final_habit_answer(
    intervention_type: str,
    habit_plan: Optional[Dict[str, Any]] = None,
    analysis_result: Optional[Dict[str, Any]] = None,
    recommendations: Optional[List[str]] = None,
    error_message: Optional[str] = None
) -> FinalHabitAnswerOutput:
    """
    Tool Purpose: Standardize the final response format for habit management interventions.
    
    Args:
    - intervention_type (str): Type of intervention: 'habit_creation', 'habit_analysis', 'habit_modification', or 'error'
    - habit_plan (Optional[Dict]): Habit plan result from main habit operations
    - analysis_result (Optional[Dict]): Analysis result from advanced analytics tools
    - recommendations (Optional[List[str]]): Recommendations generated by LLM and extended with mood-supporting habits
    - error_message (Optional[str]): Error message if intervention_type is 'error'
    
    Returns:
    - FinalHabitAnswerOutput: Validated Pydantic model with habit_plan, analysis, recommendations, intervention_type, and error_type
    """
    # Initialize default values
    habit_output = None
    analysis_output = None
    response_recommendations = []
    error_type = None
    
    if intervention_type == "error":
        error_type = "habit_intervention_error"
        response_recommendations = ["retry_request", "contact_support", "simplify_habit_goals"]
    
    elif intervention_type == "habit_creation":
        if habit_plan and habit_plan.get("success"):
            habit_output = HabitOutput(
                is_created=True,
                habit_id=habit_plan.get("epic_habits", [{}])[0].get("epic_habit_id") if habit_plan.get("epic_habits") else None,
                plan_id=habit_plan.get("plan_id")
            )
        response_recommendations = recommendations or ["start_with_smallest_habit", "track_daily_progress", "be_patient_with_formation"]
    
    elif intervention_type == "habit_analysis":
        if analysis_result:
            analysis_output = analysis_result
        response_recommendations = recommendations or ["review_analysis_insights", "adjust_habits_based_on_data", "continue_tracking"]
    
    elif intervention_type == "habit_modification":
        if habit_plan:
            habit_output = HabitOutput(
                is_created=habit_plan.get("success", False),
                habit_id=habit_plan.get("modified_habit_id"),
                plan_id=habit_plan.get("plan_id")
            )
        response_recommendations = recommendations or ["monitor_modified_habits", "adjust_as_needed", "celebrate_improvements"]
    
    return FinalHabitAnswerOutput(
        habit_plan=habit_output,
        analysis=analysis_output,
        recommendations=response_recommendations,
        intervention_type=intervention_type,
        error_type=error_type
    )

# =============================================================================
# ADVANCED ANALYTICS TOOLS (internal for LLM brain use only)
# =============================================================================

@tool("analyze_underperforming_habits", args_schema=AnalyzeUnderperformingHabitsInput)
async def analyze_underperforming_habits(
    user_id: str, time_period: str = "monthly", threshold: float = 0.3
) -> Dict[str, Any]:
    """
    Tool Purpose: Identify habits with poor completion rates and generate actionable recommendations.
    
    Args:
    - user_id (str): User identifier
    - time_period (str): Time period for analysis (weekly, monthly, custom)
    - threshold (float): Completion rate threshold below which habits are underperforming
    
    Returns:
    - Dict containing: underperforming_habits (List), analysis (Dict), recommendations (List)
    """
    # Check user tier permissions
    user_limits = get_user_habit_limits(user_id)
    
    if not user_limits["ai_insights"]:
        return {
            "success": False,
            "error": "Advanced habit analysis requires premium plan",
            "upgrade_message": "Upgrade to premium for AI-powered habit insights and underperformance analysis",
            "feature_blocked": "ai_insights"
        }
    
    # Get all user completions for period
    all_completions = await _get_all_user_completions(user_id, time_period)
    
    # Group by habit and calculate completion rates
    habit_performance = {}
    for completion in all_completions:
        habit_id = completion["habit_id"]
        if habit_id not in habit_performance:
            habit_performance[habit_id] = {"attempts": 0, "successes": 0, "scores": [], "timings": []}
        
        habit_performance[habit_id]["attempts"] += 1
        if completion["completion_score"] > 0:
            habit_performance[habit_id]["successes"] += 1
        habit_performance[habit_id]["scores"].append(completion["completion_score"])
        if completion.get("actual_timing"):
            habit_performance[habit_id]["timings"].append(completion["actual_timing"])
    
    # Identify underperforming habits
    underperforming_habits = []
    for habit_id, performance in habit_performance.items():
        completion_rate = performance["successes"] / performance["attempts"] if performance["attempts"] > 0 else 0
        
        if completion_rate < threshold:
            habit = await _get_habit_by_id(habit_id)
            avg_score = sum(performance["scores"]) / len(performance["scores"]) if performance["scores"] else 0
            
            underperforming_habits.append({
                "habit_id": habit_id,
                "habit_name": habit.get("name", "Unknown") if habit else "Unknown",
                "completion_rate": round(completion_rate, 3),
                "average_score": round(avg_score, 3),
                "attempts": performance["attempts"],
                "category": habit.get("category", "uncategorized") if habit else "uncategorized",
                "intrinsic_score": habit.get("intrinsic_score", 1) if habit else 1
            })
    
    # Sort by impact (intrinsic_score * (1 - completion_rate))
    underperforming_habits.sort(key=lambda h: h["intrinsic_score"] * (1 - h["completion_rate"]), reverse=True)
    
    # Generate recommendations
    recommendations = []
    for habit in underperforming_habits[:3]:  # Top 3 most impactful
        habit_data = await _get_habit_by_id(habit["habit_id"])
        
        if habit["completion_rate"] < 0.1:
            recommendations.append(f"Consider pausing or redesigning '{habit['habit_name']}' - extremely low completion rate")
        elif habit["completion_rate"] < 0.2:
            recommendations.append(f"Simplify '{habit['habit_name']}' or reduce frequency - too ambitious")
        elif habit["average_score"] < habit["intrinsic_score"] * 0.5:
            recommendations.append(f"Break down '{habit['habit_name']}' into smaller steps - partial completion issues")
        
        # Timing-based recommendations
        if habit_data and habit_data.get("daily_timing") and len(habit_performance[habit["habit_id"]]["timings"]) > 3:
            timing_variance = len(set(habit_performance[habit["habit_id"]]["timings"]))
            if timing_variance > 3:
                recommendations.append(f"Consider flexible timing for '{habit['habit_name']}' - timing conflicts detected")
    
    # General recommendations
    if len(underperforming_habits) > 5:
        recommendations.append("Consider habit load management - too many concurrent habits may be causing interference")
    
    return {
        "underperforming_habits": underperforming_habits,
        "analysis": {
            "total_habits_analyzed": len(habit_performance),
            "underperforming_count": len(underperforming_habits),
            "threshold_used": threshold,
            "time_period": time_period
        },
        "recommendations": recommendations,
        "success": True
    }

@tool("analyze_lagging_epic_progress", args_schema=AnalyzeLaggingEpicProgressInput)
async def analyze_lagging_epic_progress(
    user_id: str, epic_habit_id: str, target_progress_rate: Optional[float] = None
) -> Dict[str, Any]:
    """
    Tool Purpose: Analyze epic habits that are behind schedule and suggest corrective actions.
    
    Args:
    - user_id (str): User identifier
    - epic_habit_id (str): Epic habit identifier
    - target_progress_rate (Optional[float]): Expected progress rate, calculated from target date if None
    
    Returns:
    - Dict containing: epic_analysis (Dict), bottleneck_habits (List), corrective_actions (List)
    """
    # Check user tier permissions
    user_limits = get_user_habit_limits(user_id)
    
    if not user_limits["epic_progress_calculation"]:
        return {
            "success": False,
            "error": "Epic progress analysis requires premium plan",
            "upgrade_message": "Upgrade to premium for epic habit tracking and progress analysis",
            "feature_blocked": "epic_progress_calculation"
        }
    
    # Get epic habit details
    epic_habit = await _get_epic_habit_by_id(epic_habit_id)
    if not epic_habit:
        return {"success": False, "error": f"Epic habit {epic_habit_id} not found"}
    
    # Calculate current progress
    current_progress_data = await _calculate_basic_epic_progress(epic_habit_id, "all_time")
    current_progress = current_progress_data.get("overall_progress", 0)
    
    # Calculate expected progress rate
    if target_progress_rate is None:
        target_date = datetime.fromisoformat(epic_habit["target_completion_date"]).date()
        created_date = datetime.fromisoformat(epic_habit["created_date"]).date()
        current_date = datetime.now().date()
        
        total_days = (target_date - created_date).days
        elapsed_days = (current_date - created_date).days
        
        if total_days > 0:
            expected_progress = (elapsed_days / total_days) * 100
        else:
            expected_progress = 100  # Already past due
    else:
        expected_progress = target_progress_rate
    
    # Analyze gap
    progress_gap = expected_progress - current_progress
    is_lagging = progress_gap > 10  # More than 10% behind
    
    # Identify bottleneck habits (micro habits with lowest performance)
    micro_habit_progress = current_progress_data.get("micro_habit_progress", {})
    bottleneck_habits = []
    
    for habit_id, progress in micro_habit_progress.items():
        if progress["average_score"] < 0.4 or progress["consistency_rate"] < 0.5:
            habit_details = await _get_habit_by_id(habit_id)
            bottleneck_habits.append({
                "habit_id": habit_id,
                "habit_name": habit_details.get("name", "Unknown") if habit_details else "Unknown",
                "average_score": progress["average_score"],
                "consistency_rate": progress["consistency_rate"],
                "weight": progress["weight"],
                "impact_on_epic": progress["weight"] * (1 - progress["average_score"])
            })
    
    # Sort bottlenecks by impact
    bottleneck_habits.sort(key=lambda h: h["impact_on_epic"], reverse=True)
    
    # Generate corrective actions
    corrective_actions = []
    
    if is_lagging:
        corrective_actions.append(f"Epic '{epic_habit['name']}' is {progress_gap:.1f}% behind target progress")
        
        # High-impact bottleneck recommendations
        for bottleneck in bottleneck_habits[:2]:  # Top 2 bottlenecks
            if bottleneck["consistency_rate"] < 0.3:
                corrective_actions.append(f"Critical: Address '{bottleneck['habit_name']}' consistency issues - only {bottleneck['consistency_rate']*100:.1f}% completion rate")
            elif bottleneck["average_score"] < 0.3:
                corrective_actions.append(f"Improve quality of '{bottleneck['habit_name']}' - low average score")
        
        # Strategic recommendations
        if len(bottleneck_habits) > 3:
            corrective_actions.append("Consider focusing on fewer micro habits to improve quality")
        
        if progress_gap > 30:
            corrective_actions.append("Significant delay detected - consider extending target date or simplifying success criteria")
        elif progress_gap > 20:
            corrective_actions.append("Consider adding high-frequency micro habits to accelerate progress")
    
    return {
        "epic_analysis": {
            "epic_name": epic_habit["name"],
            "current_progress": current_progress,
            "expected_progress": expected_progress,
            "progress_gap": progress_gap,
            "is_lagging": is_lagging,
            "target_date": epic_habit["target_completion_date"],
            "days_remaining": (datetime.fromisoformat(epic_habit["target_completion_date"]).date() - datetime.now().date()).days
        },
        "bottleneck_habits": bottleneck_habits,
        "corrective_actions": corrective_actions,
        "success": True
    }

@tool("analyze_habit_interactions", args_schema=AnalyzeHabitInteractionsInput)
async def analyze_habit_interactions(
    user_id: str, time_period: str = "monthly", interaction_type: str = "all"
) -> Dict[str, Any]:
    """
    Tool Purpose: Detect correlations between habits - both synergistic and antagonistic relationships.
    
    Args:
    - user_id (str): User identifier
    - time_period (str): Time period for analysis
    - interaction_type (str): Type of interactions (synchronous, antagonistic, all)
    
    Returns:
    - Dict containing: synchronous_pairs (List), antagonistic_pairs (List), insights (List)
    """
    # Check user tier permissions
    user_limits = get_user_habit_limits(user_id)
    
    if not user_limits["habit_interaction_analysis"]:
        return {
            "success": False,
            "error": "Habit interaction analysis requires premium plan",
            "upgrade_message": "Upgrade to premium for habit synergy and conflict detection",
            "feature_blocked": "habit_interaction_analysis"
        }
    
    if not user_limits["habit_interaction_analysis"]:
        return {
            "success": False,
            "error": "Habit interaction analysis requires premium plan",
            "upgrade_message": "Upgrade to premium for habit synergy and conflict detection",
            "feature_blocked": "habit_interaction_analysis"
        }
    
    # Get all user completions
    all_completions = await _get_all_user_completions(user_id, time_period)
    
    # Group by date and habit
    daily_completions = {}
    for completion in all_completions:
        date = completion["date"]
        if date not in daily_completions:
            daily_completions[date] = {}
        daily_completions[date][completion["habit_id"]] = completion["completion_score"]
    
    # Get unique habits
    all_habits = set()
    for daily_data in daily_completions.values():
        all_habits.update(daily_data.keys())
    
    habit_list = list(all_habits)
    
    # Calculate correlations between habit pairs
    synchronous_pairs = []
    antagonistic_pairs = []
    
    for i, habit1 in enumerate(habit_list):
        for j, habit2 in enumerate(habit_list[i+1:], i+1):
            # Get completion scores for both habits on same days
            habit1_scores = []
            habit2_scores = []
            
            for date, habits in daily_completions.items():
                if habit1 in habits and habit2 in habits:
                    habit1_scores.append(habits[habit1])
                    habit2_scores.append(habits[habit2])
            
            if len(habit1_scores) >= 5:  # Need at least 5 data points
                correlation = _calculate_correlation(habit1_scores, habit2_scores)
                
                # Get habit details
                habit1_details = await _get_habit_by_id(habit1)
                habit2_details = await _get_habit_by_id(habit2)
                
                habit1_name = habit1_details.get("name", "Unknown") if habit1_details else "Unknown"
                habit2_name = habit2_details.get("name", "Unknown") if habit2_details else "Unknown"
                
                if correlation > 0.5 and interaction_type in ["synchronous", "all"]:
                    synchronous_pairs.append({
                        "habit1_id": habit1,
                        "habit1_name": habit1_name,
                        "habit2_id": habit2,
                        "habit2_name": habit2_name,
                        "correlation": round(correlation, 3),
                        "strength": "strong" if correlation > 0.7 else "moderate",
                        "data_points": len(habit1_scores)
                    })
                
                elif correlation < -0.3 and interaction_type in ["antagonistic", "all"]:
                    antagonistic_pairs.append({
                        "habit1_id": habit1,
                        "habit1_name": habit1_name,
                        "habit2_id": habit2,
                        "habit2_name": habit2_name,
                        "correlation": round(correlation, 3),
                        "strength": "strong" if correlation < -0.6 else "moderate",
                        "data_points": len(habit1_scores)
                    })
    
    # Sort by correlation strength
    synchronous_pairs.sort(key=lambda x: abs(x["correlation"]), reverse=True)
    antagonistic_pairs.sort(key=lambda x: abs(x["correlation"]), reverse=True)
    
    # Generate insights
    insights = []
    
    # Synchronous insights
    for pair in synchronous_pairs[:3]:  # Top 3
        insights.append(f"'{pair['habit1_name']}' and '{pair['habit2_name']}' have {pair['strength']} positive correlation - success in one supports the other")
    
    # Antagonistic insights
    for pair in antagonistic_pairs[:3]:  # Top 3
        insights.append(f"'{pair['habit1_name']}' and '{pair['habit2_name']}' have {pair['strength']} negative correlation - conflict detected")
        insights.append(f"Consider scheduling '{pair['habit1_name']}' and '{pair['habit2_name']}' at different times or reducing frequency of one")
    
    # Strategic insights
    if len(synchronous_pairs) > len(antagonistic_pairs):
        insights.append("Overall positive habit interactions detected - habits are mutually supportive")
    elif len(antagonistic_pairs) > 3:
        insights.append("Multiple habit conflicts detected - consider habit load management")
    
    return {
        "synchronous_pairs": synchronous_pairs,
        "antagonistic_pairs": antagonistic_pairs,
        "insights": insights,
        "analysis_summary": {
            "total_habit_pairs_analyzed": len(habit_list) * (len(habit_list) - 1) // 2,
            "synchronous_relationships": len(synchronous_pairs),
            "antagonistic_relationships": len(antagonistic_pairs),
            "time_period": time_period
        },
        "success": True
    }

@tool("analyze_mood_habit_correlation", args_schema=AnalyzeMoodHabitCorrelationInput)
async def analyze_mood_habit_correlation(
    user_id: str, habit_id: Optional[str] = None, time_period: str = "monthly"
) -> Dict[str, Any]:
    """
    Tool Purpose: Analyze correlation between mood states and habit completion patterns.
    
    Args:
    - user_id (str): User identifier
    - habit_id (Optional[str]): Specific habit ID or None for all habits
    - time_period (str): Time period for analysis
    
    Returns:
    - Dict containing: correlations (Dict), insights (List), recommendations (List)
    """
    # Check user tier permissions
    user_limits = get_user_habit_limits(user_id)
    
    if not user_limits["mood_correlation"]:
        return {
            "success": False,
            "error": "Mood-habit correlation analysis requires premium plan",
            "upgrade_message": "Upgrade to premium for mood tracking and habit correlation insights",
            "feature_blocked": "mood_correlation"
        }
    
    # Get mood records and habit completions for period
    mood_records = await _get_mood_records(user_id, time_period)
    
    if habit_id:
        habit_completions = await _get_completion_records(habit_id, None, None)
        habits_to_analyze = [habit_id]
    else:
        habit_completions = await _get_all_user_completions(user_id, time_period)
        habits_to_analyze = list(set([c["habit_id"] for c in habit_completions]))
    
    correlations = {}
    insights = []
    
    for h_id in habits_to_analyze:
        habit_records = [c for c in habit_completions if c["habit_id"] == h_id]
        
        # Correlate with mood scores
        mood_score_correlation = await _calculate_correlation_with_mood_scores(habit_records, mood_records)
        
        # Correlate with crisis/depression flags
        crisis_correlation = await _calculate_correlation_with_flags(habit_records, mood_records, "is_crisis")
        depression_correlation = await _calculate_correlation_with_flags(habit_records, mood_records, "is_depressed")
        
        correlations[h_id] = {
            "mood_score_correlation": mood_score_correlation,
            "crisis_impact": crisis_correlation,
            "depression_impact": depression_correlation
        }
        
        # Generate insights
        if mood_score_correlation > 0.3:
            insights.append(f"Habit {h_id} completion increases with better mood")
        elif mood_score_correlation < -0.3:
            insights.append(f"Habit {h_id} completion decreases with better mood (possibly stress-driven)")
        
        if crisis_correlation < -0.5:
            insights.append(f"Habit {h_id} significantly impacted by crisis/stress periods")
    
    # Generate recommendations based on correlations
    recommendations = await _generate_correlation_recommendations(correlations, insights)
    
    return {
        "correlations": correlations,
        "insights": insights,
        "recommendations": recommendations,
        "analysis_period": time_period,
        "habits_analyzed": len(habits_to_analyze)
    }

@tool("generate_habit_insights", args_schema=GenerateHabitInsightsInput)
async def generate_habit_insights(
    user_id: str, habit_id: Optional[str] = None, insight_type: str = "comprehensive"
) -> Dict[str, Any]:
    """
    Tool Purpose: Generate comprehensive insights about habit patterns, timing optimization, and behavioral trends.
    
    Args:
    - user_id (str): User identifier
    - habit_id (Optional[str]): Specific habit ID, or None for all habits
    - insight_type (str): Type of insights (completion_patterns, timing_optimization, comprehensive)
    
    Returns:
    - Dict containing: insights (List), patterns (Dict), recommendations (List)
    """
    # Check user tier permissions
    user_limits = get_user_habit_limits(user_id)
    
    if not user_limits["ai_insights"]:
        return {
            "success": False,
            "error": "Advanced habit insights require premium plan",
            "upgrade_message": "Upgrade to premium for AI-powered behavioral insights and pattern analysis",
            "feature_blocked": "ai_insights"
        }
    
    insights = []
    patterns = {}
    recommendations = []
    
    if habit_id:
        # Single habit analysis
        habit_details = await _get_habit_by_id(habit_id)
        if not habit_details:
            return {"success": False, "error": f"Habit {habit_id} not found"}
        
        # Get completion records
        completion_records = await _get_completion_records(habit_id, None, None)
        
        if not completion_records:
            return {
                "insights": ["Insufficient data for analysis"],
                "patterns": {},
                "recommendations": ["Continue tracking habit for better insights"],
                "success": True
            }
        
        # Completion patterns
        if insight_type in ["completion_patterns", "comprehensive"]:
            patterns["completion_patterns"] = _analyze_completion_patterns(completion_records)
            insights.extend(_generate_completion_insights(patterns["completion_patterns"], habit_details))
        
        # Timing optimization
        if insight_type in ["timing_optimization", "comprehensive"]:
            patterns["timing_patterns"] = _analyze_timing_patterns(completion_records)
            insights.extend(_generate_timing_insights(patterns["timing_patterns"], habit_details))
            recommendations.extend(_generate_timing_recommendations(patterns["timing_patterns"]))
    
    else:
        # Multi-habit analysis
        all_completions = await _get_all_user_completions(user_id, "monthly")
        
        if not all_completions:
            return {
                "insights": ["No habit data available for analysis"],
                "patterns": {},
                "recommendations": ["Start tracking habits to generate insights"],
                "success": True
            }
        
        # Overall patterns
        patterns["overall_patterns"] = _analyze_overall_patterns(all_completions)
        insights.extend(_generate_overall_insights(patterns["overall_patterns"]))
        recommendations.extend(_generate_overall_recommendations(patterns["overall_patterns"]))
    
    return {
        "insights": insights,
        "patterns": patterns,
        "recommendations": recommendations,
        "success": True
    }

# =============================================================================
# MOOD-AWARE SUGGESTIONS TOOLS
# =============================================================================
@tool("recommend_mood_supporting_habits", args_schema=RecommendMoodSupportingHabitsInput)
def recommend_mood_supporting_habits(
    mood_state: str, is_crisis: bool = False, is_depressed: bool = False, crisis_level: int = 0
) -> List[str]:
    """
    Tool Purpose: Recommend specific mood-supporting habits for stress and depression.
    
    Args:
    - mood_state (str): Current mood state ("stress" or "depression")
    - is_crisis (bool): Whether user is in crisis state
    - is_depressed (bool): Whether user is depressed
    - crisis_level (int): Crisis level 0-10 for stress gradation
    
    Returns:
    - List[str]: Recommended habit types that could support mood improvement
    """
    recommendations = []
    
    # Stress-specific recommendations with crisis level gradation
    if is_crisis or mood_state == "stress":
        if crisis_level >= 8:
            # High crisis stress
            recommendations.extend([
                "breathing_exercises",  # 2-minute breathing routine
                "emergency_grounding",  # 5-4-3-2-1 sensory grounding
                "call_support_person",  # Immediate human contact
                "crisis_safety_routine"  # Basic safety/survival habits
            ])
        elif crisis_level >= 5:
            # Medium stress
            recommendations.extend([
                "breathing_exercises",  # 5-minute breathing routine
                "short_walk",  # 10-minute outdoor walk
                "stress_journaling",  # Quick thought dump
                "gentle_stretching"  # 5-minute stress release
            ])
        else:
            # General stress
            recommendations.extend([
                "mindfulness_breaks",  # 3-minute mindfulness check-ins
                "physical_activity",  # Any movement for stress relief
                "limit_negative_inputs",  # Reduce stressful content
                "stress_prevention_routine"  # Evening wind-down
            ])
    
    # Depression-specific recommendations
    if is_depressed or mood_state == "depression":
        recommendations.extend([
            "morning_sunlight",  # 15 minutes outdoor light exposure
            "gentle_movement",  # Light stretching or yoga
            "gratitude_practice",  # Write 3 things grateful for
            "social_connection",  # Text/call one person
            "basic_self_care",  # Shower, brush teeth, get dressed
            "creative_expression"  # Any creative activity
        ])
    
    return recommendations

# =============================================================================
# ADVANCED ANALYTICS HELPER FUNCTIONS
# =============================================================================

def _calculate_correlation(x_values: List[float], y_values: List[float]) -> float:
    """Calculate Pearson correlation coefficient between two lists of values."""
    if len(x_values) != len(y_values) or len(x_values) < 2:
        return 0.0
    
    n = len(x_values)
    x_mean = sum(x_values) / n
    y_mean = sum(y_values) / n
    
    numerator = sum((x_values[i] - x_mean) * (y_values[i] - y_mean) for i in range(n))
    x_variance = sum((x - x_mean) ** 2 for x in x_values)
    y_variance = sum((y - y_mean) ** 2 for y in y_values)
    
    denominator = (x_variance * y_variance) ** 0.5
    
    if denominator == 0:
        return 0.0
    
    return numerator / denominator

def _analyze_completion_patterns(completion_records: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze completion patterns for a single habit."""
    if not completion_records:
        return {}
    
    # Group by day of week
    weekday_scores = {i: [] for i in range(7)}  # 0=Monday, 6=Sunday
    
    for record in completion_records:
        date = datetime.fromisoformat(record["date"])
        weekday = date.weekday()
        weekday_scores[weekday].append(record["completion_score"])
    
    # Calculate average by weekday
    weekday_averages = {}
    for day, scores in weekday_scores.items():
        if scores:
            weekday_averages[day] = sum(scores) / len(scores)
        else:
            weekday_averages[day] = 0
    
    # Find best and worst days
    best_day = max(weekday_averages, key=weekday_averages.get) if weekday_averages else 0
    worst_day = min(weekday_averages, key=weekday_averages.get) if weekday_averages else 0
    
    return {
        "weekday_averages": weekday_averages,
        "best_day": best_day,
        "worst_day": worst_day,
        "weekday_names": ["Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"]
    }

def _analyze_timing_patterns(completion_records: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze timing patterns for habit completion."""
    timing_data = {}
    
    for record in completion_records:
        timing = record.get("actual_timing")
        if timing:
            if timing not in timing_data:
                timing_data[timing] = []
            timing_data[timing].append(record["completion_score"])
    
    # Calculate average score by timing
    timing_averages = {}
    for timing, scores in timing_data.items():
        timing_averages[timing] = sum(scores) / len(scores)
    
    # Find optimal timing
    optimal_timing = max(timing_averages, key=timing_averages.get) if timing_averages else None
    
    return {
        "timing_averages": timing_averages,
        "optimal_timing": optimal_timing,
        "timing_variance": len(timing_data)
    }

def _analyze_overall_patterns(all_completions: List[Dict[str, Any]]) -> Dict[str, Any]:
    """Analyze overall patterns across all habits."""
    if not all_completions:
        return {}
    
    # Overall completion rate
    total_attempts = len(all_completions)
    successful_attempts = len([c for c in all_completions if c["completion_score"] > 0])
    overall_rate = successful_attempts / total_attempts if total_attempts > 0 else 0
    
    # Category performance
    category_performance = {}
    for completion in all_completions:
        # Would need to get habit details to get category
        # For now, mock implementation
        category = "general"
        if category not in category_performance:
            category_performance[category] = {"attempts": 0, "successes": 0}
        
        category_performance[category]["attempts"] += 1
        if completion["completion_score"] > 0:
            category_performance[category]["successes"] += 1
    
    return {
        "overall_completion_rate": overall_rate,
        "total_habits_tracked": len(set(c["habit_id"] for c in all_completions)),
        "category_performance": category_performance
    }

def _generate_completion_insights(patterns: Dict[str, Any], habit_details: Dict[str, Any]) -> List[str]:
    """Generate insights from completion patterns."""
    insights = []
    
    if not patterns:
        return ["Insufficient data for completion pattern analysis"]
    
    weekday_averages = patterns.get("weekday_averages", {})
    weekday_names = patterns.get("weekday_names", [])
    
    if weekday_averages:
        best_day_idx = patterns.get("best_day", 0)
        worst_day_idx = patterns.get("worst_day", 0)
        
        if best_day_idx < len(weekday_names) and worst_day_idx < len(weekday_names):
            best_day_name = weekday_names[best_day_idx]
            worst_day_name = weekday_names[worst_day_idx]
            
            insights.append(f"Best performance on {best_day_name}s (avg: {weekday_averages[best_day_idx]:.2f})")
            insights.append(f"Worst performance on {worst_day_name}s (avg: {weekday_averages[worst_day_idx]:.2f})")
            
            # Weekend vs weekday analysis
            weekend_avg = (weekday_averages.get(5, 0) + weekday_averages.get(6, 0)) / 2
            weekday_avg = sum(weekday_averages.get(i, 0) for i in range(5)) / 5
            
            if weekend_avg > weekday_avg * 1.2:
                insights.append("Significantly better performance on weekends")
            elif weekday_avg > weekend_avg * 1.2:
                insights.append("Better performance on weekdays")
    
    return insights

def _generate_timing_insights(patterns: Dict[str, Any], habit_details: Dict[str, Any]) -> List[str]:
    """Generate insights from timing patterns."""
    insights = []
    
    if not patterns:
        return ["No timing data available for analysis"]
    
    optimal_timing = patterns.get("optimal_timing")
    timing_variance = patterns.get("timing_variance", 0)
    
    if optimal_timing:
        insights.append(f"Optimal timing appears to be: {optimal_timing}")
    
    if timing_variance > 5:
        insights.append("High timing variability detected - consider establishing fixed timing")
    elif timing_variance <= 2:
        insights.append("Consistent timing pattern - good habit establishment")
    
    return insights

def _generate_timing_recommendations(patterns: Dict[str, Any]) -> List[str]:
    """Generate timing-based recommendations."""
    recommendations = []
    
    optimal_timing = patterns.get("optimal_timing")
    timing_variance = patterns.get("timing_variance", 0)
    
    if optimal_timing:
        recommendations.append(f"Consider setting fixed timing to {optimal_timing} for better consistency")
    
    if timing_variance > 5:
        recommendations.append("Reduce timing variability by choosing 2-3 preferred time slots")
    
    return recommendations

def _generate_overall_insights(patterns: Dict[str, Any]) -> List[str]:
    """Generate insights from overall patterns."""
    insights = []
    
    overall_rate = patterns.get("overall_completion_rate", 0)
    
    if overall_rate > 0.7:
        insights.append("Excellent overall habit completion rate")
    elif overall_rate > 0.5:
        insights.append("Good habit completion rate with room for improvement")
    elif overall_rate > 0.3:
        insights.append("Moderate completion rate - consider habit optimization")
    else:
        insights.append("Low completion rate - major habit strategy revision needed")
    
    return insights

def _generate_overall_recommendations(patterns: Dict[str, Any]) -> List[str]:
    """Generate recommendations from overall patterns."""
    recommendations = []
    
    overall_rate = patterns.get("overall_completion_rate", 0)
    
    if overall_rate < 0.5:
        recommendations.append("Focus on fewer habits to improve success rate")
        recommendations.append("Consider simplifying current habits")
    
    recommendations.append("Review habit load and complexity regularly")
    
    return recommendations

async def _calculate_correlation_with_mood_scores(habit_records: List[Dict], mood_records: List[Dict]) -> float:
    """Calculate correlation between habit completion and mood scores"""
    # Create date-matched pairs
    habit_by_date = {r["date"]: r["completion_score"] for r in habit_records}
    mood_by_date = {r["date"]: r["mood_score"] for r in mood_records}
    
    # Find common dates
    common_dates = set(habit_by_date.keys()) & set(mood_by_date.keys())
    
    if len(common_dates) < 3:
        return 0.0
    
    habit_scores = [habit_by_date[date] for date in common_dates]
    mood_scores = [mood_by_date[date] for date in common_dates]
    
    return _calculate_correlation(habit_scores, mood_scores)

async def _calculate_correlation_with_flags(habit_records: List[Dict], mood_records: List[Dict], flag: str) -> float:
    """Calculate correlation between habit completion and mood flags"""
    # Create date-matched pairs
    habit_by_date = {r["date"]: r["completion_score"] for r in habit_records}
    flag_by_date = {r["date"]: int(r.get(flag, False)) for r in mood_records}
    
    # Find common dates
    common_dates = set(habit_by_date.keys()) & set(flag_by_date.keys())
    
    if len(common_dates) < 3:
        return 0.0
    
    habit_scores = [habit_by_date[date] for date in common_dates]
    flag_values = [flag_by_date[date] for date in common_dates]
    
    return _calculate_correlation(habit_scores, flag_values)

async def _generate_correlation_recommendations(correlations: Dict, insights: List[str]) -> List[str]:
    """Generate recommendations based on correlation analysis"""
    recommendations = []
    
    if any("crisis" in insight for insight in insights):
        recommendations.append("Consider crisis-adaptive versions of impacted habits")
    
    if any("increases with better mood" in insight for insight in insights):
        recommendations.append("Use mood-boosting activities to support habit completion")
    
    recommendations.append("Monitor mood patterns to optimize habit timing")
    
    return recommendations

# Function removed - filtering is no longer needed since LLM generates recommendations dynamically